[["index.html", "Notions de statistiques Chapter 1 Statistiques descriptives et tests", " Notions de statistiques Pascal Bessonneau 2024-05-22 Chapter 1 Statistiques descriptives et tests Le but est de faire un peu de révision sur les statistiques descriptives et les tests statistiques. "],["statistiques-descriptives.html", "Chapter 2 Statistiques descriptives 2.1 Distribution 2.2 Indicateurs de position (mesures de tendance centrale) 2.3 Indicateur de dispersion 2.4 Les indicateurs de la loi normale 2.5 Quantiles, ex de la loi normale. 2.6 La médiane et les quantiles usuelles 2.7 Corrélations 2.8 Covariances", " Chapter 2 Statistiques descriptives Le but de ce document est de rappeler les différents indicateurs utilisés dans les statistiques descriptives. 2.1 Distribution Dans le cas qualitatif, on appele distribution la répartition des probabilités pour tous les points pour laquelle la distribution existe. p &lt;- rbinom(n=10000, size = 10,p = 0.2) barplot(prop.table(table(p))) Nous voyons pour une distribution binomiale la distribution, cela représente un lancer de dés avec ici, la somme de dix lancers, avec 0,2 la probabilité d’obtenir un 1 et 0,8 la probabilité d’obtenir un 0. Ici la probabilité d’obtenir un score de 3 est d’environ 20%. Dans le cas quantitatif, on appele distribution la répartition des probabilités pour tous les points pour laquelle la distribution existe. La plus connu est la loi normale: exemple &lt;- rnorm(1000000,0,1) plot(density(exemple),main=&quot;Loi normale&quot;,ylab=&quot;Densité&quot;) La loi normale prends deux paramètres : l’écart-type et la moyenne. Si on fait varier l’écart-type : on a une forme plus aplatie ou inversement. plot(density(rnorm(100000,0,0.5)),main=&quot;Loi normale&quot;,ylab=&quot;Densité&quot;) lines(density(rnorm(100000,0,1)),main=&quot;Loi normale&quot;,ylab=&quot;Densité&quot;) lines(density(rnorm(100000,0,1.5)),main=&quot;Loi normale&quot;,ylab=&quot;Densité&quot;) lines(density(rnorm(100000,0,2)),main=&quot;Loi normale&quot;,ylab=&quot;Densité&quot;) Si on fait varier la moyenne : la “pointe” de la courbe varie dans son positionnement. exemple &lt;- rnorm(1000000,0,1) plot(density(exemple),main=&quot;Loi normale&quot;,ylab=&quot;Densité&quot;) 2.2 Indicateurs de position (mesures de tendance centrale) La plupart des indicateurs statistiques s’inspire de la loi normale : Les indicateurs de position donnent une idée de où se répartissent les points. Le premier indicateur est la moyenne arithmétique, elle a de nombreux prolongements en mathématiques, physique, etc. Il y a des indicateurs proches comme la moyenne géométrique, la moyenne harmonique, etc. La moyenne arithmétique est la plus utilisée. 2.2.1 Moyenne arithmétqiue En statistiques, on retrouve cette moyenne dans l’ANOVA, la régression, le test de Student, etc. C’est celle qui se retrouve dans la plupart des cas dans les formules. y=rnorm(1000000,1,1) plot(density(y),main=&quot;Normale de moyenne 1&quot;,xlab=&quot;Valeurs de x&quot;,ylab=&quot;Densité&quot;) abline(v=1,lty=3) y=rchisq(1000000,10) plot(density(y),main=&quot;Loi du Chi²&quot;,xlab=&quot;Valeurs de x&quot;,ylab=&quot;Densité&quot;) abline(v=mean(y),lty=3) Dans des cas comme la loi normale, l’indicateur de position est centrale (ie. qu’il y a une symétrie). Mais souvent, la répartition des poids n’est pas symétrique et la moyenne est décalée brisant la symétrie comme dans l’illustration du Chi². 2.2.2 Autres moyennes Elles sont peu utilisées. 2.3 Indicateur de dispersion L’indicateur de dispersion le plus fréquent est l’écart-type. L’écart-type est le carré des écarts à la moyenne (arithmétique). Il vient naturellement avec la loi normale normale où 50% des observations sont à 1 écart-type autour de la moyenne. Plus l’écart-type est grand plus les écarts entre les valeurs observées et la moyenne sont grands. Les points sont plus dispersés. y=rnorm(1000000,1,1) plot(density(y),main=&quot;Normale de moyenne 1&quot;,xlab=&quot;Valeurs de x&quot;,ylab=&quot;Densité&quot;) abline(v=1,lty=3) abline(v=1-sd(y),lty=1,col=&quot;red&quot;) abline(v=1+sd(y),lty=1,col=&quot;red&quot;) text(1-sd(y)+0.5*sd(y),0.2+strheight(&quot;Ya&quot;),expression(sigma)) text(1+0.5*sd(y),0.2+strheight(&quot;Ya&quot;),expression(sigma)) arrows( 1-sd(y),0.2-strheight(&quot;Ya&quot;), 1,0.2-strheight(&quot;Ya&quot;), length=0.05,code=3 ) arrows( 1,0.2-strheight(&quot;Ya&quot;), 1+sd(y),0.2-strheight(&quot;Ya&quot;), length=0.05,code=3 ) Un écart-type et la moyenne sont de même unité : par exemple si on mesure le poids d’objets, on a par exemple moyenne et écart-type en kg. Donc si on divise la moyenne par l’écart-type, on obtient un nombre sans unité ou plutôt avec comme unité un écart-type. Ce type d’opération de diviser par l’écart-type une ou des valeurs observées est appelé réduire une variable. Cette opération est fréquemment associée au fait de soustraire par la moyenne avant de réduire. Donc les observations deviennent centrées autour de la moyenne. On appelle ces deux opérations centrer/réduire une variable soit scale en R. Quand on analyse plusieurs variables d’unités très différentes en statistiques, avec d’un côté des chiffres très grands et de l’autre côté des petits par exemple, on est amené à centrer/réduire pour manipuler des chiffres de même ordre de grandeur. 2.4 Les indicateurs de la loi normale skweness et kurtosis. La kurtose est l’aplatissement de la distribution par rapport à la loi normale. rr &lt;- rnonnorm(1000000, mean = 0, sd = 1, skew = 0, kurt = 0) r2 &lt;- rnonnorm(1000000, mean = 0, sd = 1, skew = 0, kurt = -0.5) r3 &lt;- rnonnorm(1000000, mean = 0, sd = 1, skew = 0, kurt = 3) d1 &lt;- density(rr$dat) d2 &lt;- density(r2$dat) d3 &lt;- density(r3$dat) plot(0,0,type=&quot;n&quot;, xlim=range(c(d1$x,d2$x,d3$x)), ylim=range(c(d1$y,d2$y,d3$y)), main = &quot;&quot;, xlab=&quot;Valeurs&quot;, ylab=&quot;Densité&quot; ) lines(d1,lty=1,col=brewer.pal(3,name = &quot;Set2&quot;)[1]) lines(d2,lty=2,col=brewer.pal(3,name = &quot;Set2&quot;)[2]) lines(d3,lty=3,col=brewer.pal(3,name = &quot;Set2&quot;)[3]) legend(&quot;topright&quot;,c(&quot;Kurtose = 0&quot;,&quot;Kurtose = -0.5&quot;,&quot;Kurtose = 3&quot;), lty=c(1,2,3), col=brewer.pal(3,name = &quot;Set2&quot;)) Le coefficient d’asymétrie ou skewness indique lui la symatrie par rapport à l’axe centrale de la distribution normale. rr &lt;- rnonnorm(9000000, mean = 0, sd = 1, skew = 0 , kurt = 0) r2 &lt;- rnonnorm(9000000, mean = 0, sd = 1, skew = -0.5, kurt = 0) r3 &lt;- rnonnorm(9000000, mean = 0, sd = 1, skew = 0.5, kurt = 0) d1 &lt;- density(rr$dat) d2 &lt;- density(r2$dat) d3 &lt;- density(r3$dat) plot(0,0,type=&quot;n&quot;, xlim=range(c(d1$x,d2$x,d3$x)), ylim=range(c(d1$y,d2$y,d3$y)), main = &quot;&quot;, xlab=&quot;Valeurs&quot;, ylab=&quot;Densité&quot; ) lines(d1,lty=1,col=brewer.pal(3,name = &quot;Set2&quot;)[1]) lines(d2,lty=2,col=brewer.pal(3,name = &quot;Set2&quot;)[2]) lines(d3,lty=3,col=brewer.pal(3,name = &quot;Set2&quot;)[3]) legend(&quot;topright&quot;,c(&quot;Skewness = 0&quot;,&quot;Skewness = -0.5&quot;,&quot;Skewness = 0.5&quot;), lty=c(1,2,3), col=brewer.pal(3,name = &quot;Set2&quot;)) 2.5 Quantiles, ex de la loi normale. Les quantiles représentent la proportion d’individus qui se retrouvent en deça d’une valeur. Par exemple, pour une loi normale : rr &lt;- rnorm(1000000) dd &lt;- density(rr) plot(0,0,type=&quot;n&quot;,main=&quot;&quot;,xlab=&quot;Valeurs&quot;,ylab=&quot;Densité&quot;, xlim=range(dd$x),ylim=range(dd$y)) lines(dd) polygon(c(dd$x[dd$x &lt; -1],rev(dd$x[dd$x &lt; -1])), c(dd$y[dd$x &lt; -1],rep(0,length(dd$y))[dd$x &lt; -1]), col=rgb(0,0,1,0.5),border = NA) abline(v=-1) text(-3,0.3,paste(round(100*pnorm(-1),2),&quot; % en deça de &quot;,round(-1,2))) plot(0,0,type=&quot;n&quot;,main=&quot;&quot;,xlab=&quot;Valeurs&quot;,ylab=&quot;Densité&quot;, xlim=range(dd$x),ylim=range(dd$y)) lines(dd) polygon(c(dd$x[dd$x &lt; 1],rev(dd$x[dd$x &lt; 1])), c(dd$y[dd$x &lt; 1],rep(0,length(dd$y))[dd$x &lt; 1]), col=rgb(0,1,0,0.5),border = NA) abline(v=1) text(-3,0.3,paste(round(100*pnorm(1),2),&quot; % en deça de &quot;,round(1,2))) plot(0,0,type=&quot;n&quot;,main=&quot;&quot;,xlab=&quot;Valeurs&quot;,ylab=&quot;Densité&quot;, xlim=range(dd$x),ylim=range(dd$y)) lines(dd) polygon(c(dd$x[dd$x &lt; 1],rev(dd$x[dd$x &lt; 1])), c(dd$y[dd$x &lt; 1],rep(0,length(dd$y))[dd$x &lt; 1]), col=rgb(0,1,0,0.5),border = NA) abline(v=1) text(-3,0.3,paste(100*round(pnorm(1),2),&quot; % en deça de &quot;,round(1,2))) Soit entre la moyenne et les écart-types pour la loi normale, il y a 68 % des individus. plot(0,0,type=&quot;n&quot;,main=&quot;&quot;,xlab=&quot;Valeurs&quot;,ylab=&quot;Densité&quot;, xlim=range(dd$x),ylim=range(dd$y)) lines(dd) polygon(c(dd$x[dd$x &gt; -1 &amp; dd$x &lt; 1],rev(dd$x[dd$x &gt; -1 &amp; dd$x &lt; 1])), c(dd$y[dd$x &gt; -1 &amp; dd$x &lt; 1],rep(0,length(dd$y))[dd$x &gt; -1 &amp; dd$x &lt; 1]), col=rgb(0,1,0,0.5),border = NA) abline(v=-1,lty=3) abline(v= 1,lty=3) text(-3,0.3,paste(100*round(pnorm(1) - pnorm(-1),2),&quot; % entre -1 et 1&quot;)) Entre les valeurs, les quantiles -2 et 2, il y a 95 % des individus. Les valeurs pour -2 et 2 sont respectivement -1,96 et 1,96. 2.6 La médiane et les quantiles usuelles La médiane est le quantile le plus connu : il sépare 50% des individus à gauche et 50 % des individus à droite. Quand la fonction est symétrique, la médiane est égale à la moyenne. La médiane est souvent utilisé comme indicatrice de tendance centrale dans le cas où la fonction est très asymétrique où s’il y a des valeurs extrêmes : rr &lt;- c(rnorm(1000),rnorm(5,10)) plot(density(rr)) la moyenne est de 0.0524712 et l’écart-type de 1.184008. La moyenne sans les points extrêmes est de 0.0043235 tandis que la médiane est de 0.0391303 avec et de 0.0341976. Les autres quantiles quantiles les plus fréquents sont les quartiles : 0%, 25%, 50%, 75%, 100%. 2.7 Corrélations set.seed(42) rx &lt;- runif(100,0,4) ry &lt;- 0.8*rx+rnorm(100,sd=0.5) plot(rx,ry,pch=20) set.seed(42) rx &lt;- runif(100,0,4) ry &lt;- 0.8*rx+rnorm(100,sd=0.5) plot(rx,ry,pch=20) rr &lt;- lm(ry~rx) abline(rr) pos &lt;- which.max(ry) arrows(rx[pos],predict(rr)[pos],rx[pos],ry[pos],length=0.05,code = 3) print(rr) ## ## Call: ## lm(formula = ry ~ rx) ## ## Coefficients: ## (Intercept) rx ## -0.1269 0.8545 set.seed(42) rx &lt;- runif(100,-4,4) ry &lt;- runif(100,-4,4) plot(rx,ry,pch=20) rr &lt;- lm(ry~rx) abline(rr) set.seed(42) rx &lt;- runif(100,-4,4) ry &lt;- cos(rx)+rnorm(100,sd=0.25) plot(rx,ry,pch=20) rr &lt;- lm(ry~rx) abline(rr) print(rr) ## ## Call: ## lm(formula = ry ~ rx) ## ## Coefficients: ## (Intercept) rx ## -0.221598 -0.002439 set.seed(42) rx &lt;- runif(100,-4,4) ry &lt;- rx^2+rnorm(100,sd=1) plot(rx,ry,pch=20) rr &lt;- lm(ry~rx) abline(rr) rr ## ## Call: ## lm(formula = ry ~ rx) ## ## Coefficients: ## (Intercept) rx ## 5.77183 0.09141 a &lt;- lm(ry ~ rx + I(rx^2)) plot(rx,ry,pch=20) points(rx[order(rx)],predict(a)[order(rx)],col=rgb(0,0,1),type=&quot;l&quot;) set.seed(42) rx &lt;- runif(1000,-4,4) rx &lt;- c(rx[rx &gt;= -4 &amp; rx &lt; -3],rx[rx &gt;= -3 &amp; rx &lt; 0],rx[rx&gt;=0 &amp; rx &lt; 2],rx[rx &gt;= 2 &amp; rx &lt;= 4]) ry &lt;- c(3*rx[rx&gt;= -4 &amp; rx&lt; -3],-4*rx[rx&gt;= -3 &amp; rx&lt; 0],0.2*rx[rx &gt;= 0 &amp; rx&lt;2],6*rx[rx&gt;=2 &amp; rx&lt;=4]) ry &lt;- ry+rnorm(length(ry),sd=0.5) plot(rx,ry,pch=20) rr &lt;- lm(ry~rx) library(splines) a &lt;- lm(ry ~ ns(rx, df = 4)) plot(rx,ry,pch=20) points(rx[order(rx)],predict(a)[order(rx)],col=rgb(0,0,1),type=&quot;l&quot;) 2.8 Covariances Les covariances sont les carrées des écarts entre les valeurs prises par deux variables aléatoires. En fait ce sont les corrélations mais avec comme unités les unités naturelles des deux variables et non des écart-types comme unités. Cela peut être très utile quand on calcule des corrélations entre des grands nombres et des petits nombre. Cela peut être difficile de lire les covariances donc on est amené à réduire les variables. Par exemple : Réduire les covariances équivaut à calculer la corrélation. "],["tests.html", "Chapter 3 Tests 3.1 Convergence vers la loi normale 3.2 Test Z 3.3 Test de Student 3.4 Erreur de Type I et II 3.5 Tests “paramétriques” et non paramétriques 3.6 Précautions à prendre quand on travaille avec des tests", " Chapter 3 Tests 3.1 Convergence vers la loi normale Si on tire des échantillons aléatoirement, alors la moyenne de ces échantillons va converger vers une loi normale de moyenne m et d’écat-type sigma. Central Limit Theorem 3.2 Test Z Le test Z est le calcul de la position de la loi normale par rapport à ces quantiles. On prend une variable que l’on centre/réduit si besoin. Alors si on moins de xx % de chances que la moyenne se trouve entre les valeurs (positives et négatives) des quantiles alors la différence entre la moyenne de la loi normale réduite est différente de m, une valeur théorique fixée. Schématiquement on utilise les quantiles de la loi normale. Si la moyenne se distribue comme une loi normale alors, entre doit se trouver avec une confiance de 95% entre les deux quantiles qui englobe 95% des observations d’une loi normale. On a : 100 - 95 = 5% Comme on tient compte des observations à gauche et à droite alors on a le quantile de 2,5% à gauche et 97,5% à droite. y=rnorm(1000000,0,1) dd=density(y) plot(dd,main=&quot;Normale de moyenne 0&quot;,xlab=&quot;Valeurs de x&quot;,ylab=&quot;Densité&quot;) abline(v=0,lty=3) abline(v=0-1.96*sd(y),lty=1,col=rgb(1,0,0,0.5)) abline(v=0+1.96*sd(y),lty=1,col=rgb(1,0,0,0.5)) polygon(c(dd$x[dd$x&gt;-1.96 &amp; dd$x&lt;1.96],rev(dd$x[dd$x&gt; -1.96 &amp; dd$x&lt;1.96])),c(rep(0,length(dd$y))[dd$x&gt; -1.96 &amp; dd$x&lt;1.96],rev(dd$y[dd$x&gt; -1.96 &amp; dd$x&lt;1.96])),col=rgb(1,0,0,0.5)) Le test est donc : Si la distribution de la moyenne suit une loi normale centrée/réduite, sous l’hypothèse nulle que m = m0 alors si m est compris entre -1,96 et 1,96 alors m n’est pas différent de m0. Sinon m est différent de m0 avec un seuil de 5%. set.seed(42) r0 &lt;- rnorm(100) r1 &lt;- rnorm(100,mean=0.25) r3 &lt;- rnorm(100,mean=0.5) plot(density(r0),xlim=c(-3,6),ylim=range(c(density(r0)$y,density(r1)$y,density(r3)$y))) abline(v=mean(r0),lty=2) points(density(r1),col=&quot;blue&quot;,type = &quot;l&quot;) abline(v=mean(r1),lty=2,col=&quot;blue&quot;) points(density(r3),col=&quot;green&quot;,type = &quot;l&quot;) abline(v=mean(r3),lty=2,col=&quot;green&quot;) z &lt;- sqrt(length(r1))*(mean(r1)-0)/sd(r1) z ## [1] 1.797402 abs(z) &gt; 1.96 ## [1] FALSE z &lt;- sqrt(length(r3))*(mean(r3)-0)/sd(r3) z ## [1] 4.814414 abs(z) &gt; 1.96 ## [1] TRUE Question : que se passe-t-il si on fait un test seulement à droite ou seulement à gauche ? C’est à dire si on s’intéresse non pas au cas où m est autour de m0 mais si m est plus grand que m0 ou plus petit que m0. 3.3 Test de Student Le test de Student est similaire au test Z, il est même identique dans certains cas. Les test de Student a deux fonctions : tester si une variable a une moyenne différente de m0. test si les moyenne de deux variables sont différentes On reconnait le premier cas qui est le test Z. D’ailleurs ont retrouve la même valeur pour le test : t.test(r1) ## ## One Sample t-test ## ## data: r1 ## t = 1.7974, df = 99, p-value = 0.07532 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -0.01689135 0.34192394 ## sample estimates: ## mean of x ## 0.1625163 Le test de Student est proche de l’ANOVA. En fait les résultats sont identiques quand il y a l’argument var.equal=TRUE. Il signifie que les variances des variables sont identiques. Un exemple du test de Student, n’est pas sur deux variable séparée mais entre deux catégories d’individus qui forme chacun une population : t.test( iris$Sepal.Length[iris$Species==&quot;setosa&quot;], iris$Sepal.Length[iris$Species==&quot;versicolor&quot;], var.equal = T ) ## ## Two Sample t-test ## ## data: iris$Sepal.Length[iris$Species == &quot;setosa&quot;] and iris$Sepal.Length[iris$Species == &quot;versicolor&quot;] ## t = -10.521, df = 98, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.1054165 -0.7545835 ## sample estimates: ## mean of x mean of y ## 5.006 5.936 Le résultat est assez intuitif si on regarde le graphique des deux distributions : plot(density(iris$Sepal.Length[iris$Species==&quot;setosa&quot;]),type=&quot;l&quot;,main=&quot;&quot;, xlab=&quot;Taille&quot;,ylab=&quot;Densité&quot;) points(density(iris$Sepal.Length[iris$Species==&quot;versicolor&quot;]),type=&quot;l&quot;,col=&quot;blue&quot;) Pour résumer un test statistique est caractérisé : par des prérequis de travail (le plus souvent la normalité, égalité des variances, etc.). des hypothèses pour le test qui définir les conclusions que l’on peut tirer du test. A votre niveau les hypothèses sont le plus souvent binaires. Oui/non : H0 contre H1. le calcul de la valeur du test qui va être comparé aux “tables” de valeurs le calcul des degrés de liberté la conclusion du test : acceptation/rejet de H0 et idem pour H1. Certaines statistiques dites “bayésiennes” fonctionnent différemment. Elles touchent surtout la façon de définir et de calculer les tests. La méthode décrite ici est appelé, à l’opposé de bayésiennes, la méthode fréquentiste. 3.4 Erreur de Type I et II L’erreur de type I est : une erreur de type I survient dans un test d’hypothèse statistique lorsqu’une hypothèse nulle, qui est en réalité vraie, est rejetée par erreur. Les erreurs de type I sont également connues sous le nom de “faux positifs”, elles représentent la détection d’un effet positif alors qu’il n’existe aucun effet en réalité. L’erreur de type II est : le risque de ne pas démontrer que deux groupes sont différents alors qu’ils le sont dans la réalité. La puissance est 1 - l’erreur de type II. Par exemple, dans le cadre d’une étude randomisée en double aveugle pour le développement d’un nouveau médicament, le risque de 2e espèce β peut être la probabilité de conclure qu’un médicament n’est pas meilleur qu’un placebo alors qu’il l’est. Dans ce cas, la puissance du test serait la probabilité de conclure que le médicament est meilleur que le placébo, ce qui est vrai. 3.5 Tests “paramétriques” et non paramétriques Dans le premier cas, tests paramétriques, ce sont les tests que l’on vient de voir. Il repose sur des hypothèses de distribution : en l’occurence ici que les données suivent une loi normale avec des paramètres : la moyenne et l’écart-type. Le test ne “fonctionne” donc que dans le cas où ces trois élements sont présents et corrects statistiquement. Par exemple, si la distribution est très asymétrique, l’écart-type, la moyenne et la loi normale ne sont pas au rendez-vous alors il faut se tourner vers d’autres tests, en général des tests dits non-paramètriques. Ces tests ne font pas d’hypothèse sur la distribution. Par exemple pour le test de Student, l’équivalent est le test de Wilcoxon-Mann-Whitney. Ce dernier pour illustrer le propos est basé sur les rangs des observations plutôt que sur la valeur. Comme la médiane, cela rend le test plutôt robuste à l’asymétrie et aux valeurs extrèmes. L’inconvénient de ces tests est que pour un type I donné la puissance est plus faible : on a des chances plus faibles de détecter un vrai positif qu’avec 3.6 Précautions à prendre quand on travaille avec des tests Ces préquis sont à vérifier avant de faire le test Il faut comparer le nombre de degrés de liberté avec le nombre d’observations. En effet il y a des “rules of thumb” qui définissent le nombre de degrés de liberté en fonction du nombre d’observations. Par exemple pour les analyses structurales il faut de 20 à 40 observations minimums par degré de liberté. Le choix est binaire. la p-value ne donne pas de renseignements sur la “force” du test. Le choix de la valeur seuil de la p-value doit être fait en amont et doit être contrôlé par des procédures statistiques si vous calculez de nombreux tests : cela s’appele correction de Bonferroni, Tukey, etc. "],["régressions.html", "Chapter 4 Régressions 4.1 Introduction 4.2 Régression linéaire 4.3 Régression logistique 4.4 Sélection des variables", " Chapter 4 Régressions 4.1 Introduction Sous le terme de régression se cache de nombreux modèles: parmi les plus simples en statistiques comme la régression linéaire et pour aller jusqu’à des modèles très complexes comme les modèles multiniveaux, la régression quantile, etc. La présentation ici ne se veut pas exhaustive. Nous présenterons que les régressions couramment utilisées dans en psychologie. 4.2 Régression linéaire La régression linéaire est la plus simple des régressions. Elle suppose des relations linéaires entre les variables comme pour la corrélation. La variable à expliquer est continue et les variables explicatives sont quantitatives ou qualitatives. Avant de faire de la modélisation, il est impératif de faire des statistiques descriptives des données. 4.2.1 Simple Dans les statistiques descriptives, nous avons vu la corrélation. La régression linéaire simple n’est qu’une extension de la corrélation. Il y a une variable à expliquer et une variable explicative. \\(y=ax+b+\\epsilon\\) En R, avec une variable x et y, on écrit cette formule de façon presque identique : lm(y~x,data=my.data) Le tide remplace le signe égal et on spécifie la data.frame avec l’option data. Dans le calcul par la fonction lm, il y a automatiquement le calcul du terme a, la corrélation et le terme b. Comme cela a été vu dans le chapitre sur la corrélation il est d’observer une relation linéaire entre la variable à expliquer et la variable explicative. Sinon il faut faire appliquer des transformations à la variable explicative. Cela suppose des liens linéaires entre la variable à expliquer et les variables explicatives. Par rapport à la corrélation, il y a un terme supplémentaire qui s’appelle en anglais l’intercept ou ordonnée à l’origine. plot(Sepal.Length~Petal.Width,data=iris,pch=20) abline(lm(Sepal.Length~Petal.Width,data=iris)) lm(Sepal.Length~Petal.Width,data=iris) ## ## Call: ## lm(formula = Sepal.Length ~ Petal.Width, data = iris) ## ## Coefficients: ## (Intercept) Petal.Width ## 4.7776 0.8886 Le coefficient entre la variable à expliquer et la variable explcative est de 0,8886 tandis que l’ordonnée à l’origine est à 4.7776. Si vous regardez sur le graphique, l’ordonnée à l’origine est la valeur de \\(y\\) quand \\(x=0\\). Ici pour la longueur des pétales et des sépales, l’intercept est la valeur pour une longueur nulle ce qui n’a pas de sens pratique. Aussi dans certains cas nous sommes amenés à centrer la variable en soutrayant la moyenne de la variable explicative pour avoir une valeur qui a du sens: en centrant la variable l’ordonnée à l’origine est la valeur de la variable à expliquer pour la valeur moyenne de la variable explicative. lm(Sepal.Length~I(Petal.Width-mean(Petal.Width)),data=iris) ## ## Call: ## lm(formula = Sepal.Length ~ I(Petal.Width - mean(Petal.Width)), ## data = iris) ## ## Coefficients: ## (Intercept) I(Petal.Width - mean(Petal.Width)) ## 5.8433 0.8886 La valeurs pour la moyenne est donc de 5,8433 pour la valeur moyenne de Petal.width. Ce qui a plus de sens. Sous R, on peut réaliser des calculs, des transformations de la valeur directement dans la régression comme c’est le cas dans l’exemple précédent avec l’opérateur I(). On peut l’utiliser pour ajouter le calcul d’un log par exemple. 4.2.2 Multiple La relation linéaire ne doit pas forcement être visible entre la variable à expliquer et les variables explicatives prises 2 à 2. En effet pour la régression linéaire multiple les autres variables rentrent en jeu ce qui a pour conséquence de rendre plus complexe la vérification de la relation linéraire. \\(y=b_1x_1+b_2x_2+...+b_ix_i+b_0+\\epsilon\\) Comme pour la régression précédente on utilise le ~ pour séparer à gauche la variable à expliquer des variables explicatives à droite. Les variables explicatives sont séparées par des +. lm(Sepal.Length~Sepal.Width+Petal.Width+Petal.Length,data=iris) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length, ## data = iris) ## ## Coefficients: ## (Intercept) Sepal.Width Petal.Width Petal.Length ## 1.8560 0.6508 -0.5565 0.7091 Là également on peut avoir envie de donner sens à la valeur de l’intercept. Il faut dans ce cas là enlever la moyenne à chaque variable pour centrer le modèle. Toujours avec l’opérateur I(). Si on veut savoir quel est le coefficient qui impacte le plus la variable explicative, on peut comparer les pentes. Si on veut comparer les coefficients il faut qu’ils soient dans la même unité. Dans ce cas la méthode usuelle est de diviser par l’écart-type les variables explicatives et éventuellement la variable à expliquer. Cela donne des coefficients standardisés dont la valeur absolue de la taille indique l’amplitude de l’effet sur chacun des coefficients. iris.std &lt;- iris %&gt;% mutate(across(where(is.numeric), scale)) (modele=lm(Sepal.Length~Sepal.Width+Petal.Width+Petal.Length,data=iris.std)) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length, ## data = iris.std) ## ## Coefficients: ## (Intercept) Sepal.Width Petal.Width Petal.Length ## -1.176e-16 3.426e-01 -5.122e-01 1.512e+00 4.2.3 Les diagnostics pour les deux types de régressions linéaires Avant de regarder les résultats, il faut vérifier que les diagnostics sont corrects. En effet pour interpréter les résultats et notamment l’inférence (comme les tests sur les coefficients par exemple) il faut qu’un certain nombre d’hypothèses soient vérifiées: Non colinéarité des variables explicatives: aucune variable ne doit être une combinaison linéaire d’une autre variable. Indépendance des erreurs: les erreurs sont indépendantes entre observations Exogénéité : la taille des résidus doit être indépendante de la variable explicatives Homoscédasticité : la variance des erreurs est constante Normalité des termes d’erreur : la distribution des termes d’erreurs doit être aléatoire et suivre une loi normale La non colinéarité se vérifie simplement en calculant le modèle. En effet la matrice est non inversible ou n’est pas de plein rang quand il y a des variables colinéaires. Certains tests plus complexe existent pour vérifier cette hypothèse notamment lorsqu’on a beaucoup de variables. L’indépendance des résidus est rarement testé, il existe des tests comme le test de Durbin-Watson pour tester si les résidus sont auto-corrélés. library(car) durbinWatsonTest(modele) ## lag Autocorrelation D-W Statistic p-value ## 1 -0.03992126 2.060382 0.798 ## Alternative hypothesis: rho != 0 Si le test n’est pas significatif alors il n’y a pas d’auto-corrélation. Les autres hypothèses s’évaluent à l’aide des graphiques de diagnostics automatiques de R la plupart du temps : plot(modele) Le premier graphique Residuals vs Fitted permet de tester l’exogénéité. Si on observe pas de corrélation ou de structure entre les valeurs prédites et les résidus alors l’hypothèse est vérifiée. L’homoscédasticité et la normalité sont testés à l’aide du premier et second graphique qui permet de tester si la répartition suit une loi normale avec un graphique QQ plot. Si les points se distribuent sur la droite lors la distribution des résidus suit une loi normale. Les autres graphiques permettent de répérer les observations avec des valeurs extrêmes pour les résidus et les valeurs prédites. Dans le cas d’une régression avancée, il convient de vérifier les valeurs prises par ces observations extrêmes qui sont repérées par leurs numéros dans le data.frame. 4.2.4 L’interprétation des sorties Les sorties sont les suivantes : summary(modele) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length, ## data = iris.std) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.00012 -0.26555 0.02264 0.23802 1.02129 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.176e-16 3.102e-02 0.000 1 ## Sepal.Width 3.426e-01 3.508e-02 9.765 &lt; 2e-16 *** ## Petal.Width -5.122e-01 1.174e-01 -4.363 2.41e-05 *** ## Petal.Length 1.512e+00 1.209e-01 12.502 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3799 on 146 degrees of freedom ## Multiple R-squared: 0.8586, Adjusted R-squared: 0.8557 ## F-statistic: 295.5 on 3 and 146 DF, p-value: &lt; 2.2e-16 Le tableau donne la valeur des coefficients (Intercept et coefficients beta) dans la colonne Estimate. L’erreur standard associée à l’estimation des coefficients, Std. Error, la valeur du test et la p-value qui indique si le coefficient est non nul: si la p-value est inférieure au seuil fixé (généralement 0,05) alors le coefficient est significativement différent de 0. Regarder la valeur de l’erreur standard (Std Error) est important car si elle est très grande au regard des coefficients par exemple cela indique généralement que les hypothèses ne sont pas respectés et qu’il y a un problème d’identification du modèle. Ensuite les résultats sont le Multiple R-square qui indique le R², c’est-à-dire la variance expliquée par le modèle. Une valeur le plus proche de 1 est ce que l’on cherche. Dans les sciences humaines des valeurs de coeffcients proche de 0,3 reste satisfaisant. les résultats sont le Adjusted R-square est équivalent au R² mais il est pondéré par la complexité du modèle. En effet plus il y a de variable explicatrice plus le modèle va être explicatif. Mécaniquement. Aussi ce coefficient permet de pondérer le R² avec le nombre de variables pour limiter cet effet. Le F-statistic et la p-value associée sur la dernière ligne donne un test de la non nullité du R². En pratique ce test n’est pas très utile. 4.2.5 Comprendre la régression avec des variables qualitatives Jusqu’ici les variables étaient des variables quantitatives. Il fallait interpréter la pente des variables pour avoir une idée des effets sur la variable à expliquer. Dans le cas d’une variable explicative, l’interprétation est légèrement différente. Pour bien comprendre, on va dichotomiser une variable qualitative : set.seed(42) head(model.matrix(~Species-1,data=iris)[sample(1:nrow(iris)),]) ## Speciessetosa Speciesversicolor Speciesvirginica ## 49 1 0 0 ## 65 0 1 0 ## 74 0 1 0 ## 146 0 0 1 ## 122 0 0 1 ## 150 0 0 1 On a trois espèces, quand R va ajouter cette variable, il va dichotomiser la variable. Nous aurons par exemple dans l’équation (première ligne) : \\(y=b_1x_1+b_2x_2+...+b_ix_i+b_Setosa*1+b_Versicolor*0+b_Virginica*0+b_0+\\epsilon\\) soit \\(y=b_1x_1+b_2x_2+...+b_ix_i+b_Setosa*1+b_0+\\epsilon\\) ou (deuxième ligne) \\(y=b_1x_1+b_2x_2+...+b_ix_i+b_Setosa*0+b_Versicolor*1+b_Virginica*0+b_0+\\epsilon\\) soit \\(y=b_1x_1+b_2x_2+...+b_ix_i+b_Versicolor*1+b_0+\\epsilon\\) Le x va être 0 ou 1. Par conséquent, cela ne va pas modifier la pente mais l’ordonnée à l’origine du point. De plus si on laisse les trois variables alors nous allons avoir un souci. En effet les trois modalités, si elles sont toutes présentes vont être colinéaires: si Setosa est à 1 alors Versicolor et Virginica sont à 0. C’est mécanique. Nous violerions alors une hypothèse du modèle. Donc nous allons enlever une des modalités que nous allons appeler modalité de référence. Donc l’intercept sera calculé avec cette modalité de référence: il faudra lire, l’intercept quand l’espèce est setosa vaut. Quand l’iris sera versicolor ou virginica, il faudra lire par rapport à une plante Setosa l’intercept quand l’espèce est versicolor vaut. Par défaut quand on rajoute une variable qualitative (un facteur) R utilise comme valeur de référence la première modalité pour une facteur ordonné ou bien la première dans l’ordre alphabétique. Pour changer ce comportement, il faut taper : (modele=lm(Sepal.Length~Sepal.Width+Petal.Width+Petal.Length+relevel(Species,ref=&quot;versicolor&quot;),data=iris.std)) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length + ## relevel(Species, ref = &quot;versicolor&quot;), data = iris.std) ## ## Coefficients: ## (Intercept) Sepal.Width ## -0.1705 0.2610 ## Petal.Width Petal.Length ## -0.2901 1.7678 ## relevel(Species, ref = &quot;versicolor&quot;)setosa relevel(Species, ref = &quot;versicolor&quot;)virginica ## 0.8738 -0.3622 summary(modele) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length + ## relevel(Species, ref = &quot;versicolor&quot;), data = iris.std) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.95915 -0.26416 0.01085 0.24460 0.88282 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.17053 0.07842 -2.175 0.03130 * ## Sepal.Width 0.26102 0.04530 5.761 4.87e-08 *** ## Petal.Width -0.29010 0.13918 -2.084 0.03889 * ## Petal.Length 1.76781 0.14609 12.101 &lt; 2e-16 *** ## relevel(Species, ref = &quot;versicolor&quot;)setosa 0.87380 0.29004 3.013 0.00306 ** ## relevel(Species, ref = &quot;versicolor&quot;)virginica -0.36221 0.14369 -2.521 0.01280 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3705 on 144 degrees of freedom ## Multiple R-squared: 0.8673, Adjusted R-squared: 0.8627 ## F-statistic: 188.3 on 5 and 144 DF, p-value: &lt; 2.2e-16 ou bien iris.std$Species2 &lt;- relevel(iris.std$Species,ref=&quot;versicolor&quot;) (modele=lm(Sepal.Length~Sepal.Width+Petal.Width+Petal.Length+Species2,data=iris.std)) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length + ## Species2, data = iris.std) ## ## Coefficients: ## (Intercept) Sepal.Width Petal.Width Petal.Length Species2setosa Species2virginica ## -0.1705 0.2610 -0.2901 1.7678 0.8738 -0.3622 summary(modele) ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width + Petal.Width + Petal.Length + ## Species2, data = iris.std) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.95915 -0.26416 0.01085 0.24460 0.88282 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.17053 0.07842 -2.175 0.03130 * ## Sepal.Width 0.26102 0.04530 5.761 4.87e-08 *** ## Petal.Width -0.29010 0.13918 -2.084 0.03889 * ## Petal.Length 1.76781 0.14609 12.101 &lt; 2e-16 *** ## Species2setosa 0.87380 0.29004 3.013 0.00306 ** ## Species2virginica -0.36221 0.14369 -2.521 0.01280 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3705 on 144 degrees of freedom ## Multiple R-squared: 0.8673, Adjusted R-squared: 0.8627 ## F-statistic: 188.3 on 5 and 144 DF, p-value: &lt; 2.2e-16 Il est à noter qu’on peut utiliser gtsummary : modele |&gt; tbl_regression() |&gt; bold_labels() #nnzaecvzmk table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #nnzaecvzmk thead, #nnzaecvzmk tbody, #nnzaecvzmk tfoot, #nnzaecvzmk tr, #nnzaecvzmk td, #nnzaecvzmk th { border-style: none; } #nnzaecvzmk p { margin: 0; padding: 0; } #nnzaecvzmk .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nnzaecvzmk .gt_caption { padding-top: 4px; padding-bottom: 4px; } #nnzaecvzmk .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nnzaecvzmk .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #nnzaecvzmk .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nnzaecvzmk .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nnzaecvzmk .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nnzaecvzmk .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nnzaecvzmk .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nnzaecvzmk .gt_column_spanner_outer:first-child { padding-left: 0; } #nnzaecvzmk .gt_column_spanner_outer:last-child { padding-right: 0; } #nnzaecvzmk .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nnzaecvzmk .gt_spanner_row { border-bottom-style: hidden; } #nnzaecvzmk .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #nnzaecvzmk .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nnzaecvzmk .gt_from_md > :first-child { margin-top: 0; } #nnzaecvzmk .gt_from_md > :last-child { margin-bottom: 0; } #nnzaecvzmk .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nnzaecvzmk .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #nnzaecvzmk .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #nnzaecvzmk .gt_row_group_first td { border-top-width: 2px; } #nnzaecvzmk .gt_row_group_first th { border-top-width: 2px; } #nnzaecvzmk .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nnzaecvzmk .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #nnzaecvzmk .gt_first_summary_row.thick { border-top-width: 2px; } #nnzaecvzmk .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nnzaecvzmk .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nnzaecvzmk .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nnzaecvzmk .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #nnzaecvzmk .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nnzaecvzmk .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nnzaecvzmk .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nnzaecvzmk .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nnzaecvzmk .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nnzaecvzmk .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nnzaecvzmk .gt_left { text-align: left; } #nnzaecvzmk .gt_center { text-align: center; } #nnzaecvzmk .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nnzaecvzmk .gt_font_normal { font-weight: normal; } #nnzaecvzmk .gt_font_bold { font-weight: bold; } #nnzaecvzmk .gt_font_italic { font-style: italic; } #nnzaecvzmk .gt_super { font-size: 65%; } #nnzaecvzmk .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #nnzaecvzmk .gt_asterisk { font-size: 100%; vertical-align: 0; } #nnzaecvzmk .gt_indent_1 { text-indent: 5px; } #nnzaecvzmk .gt_indent_2 { text-indent: 10px; } #nnzaecvzmk .gt_indent_3 { text-indent: 15px; } #nnzaecvzmk .gt_indent_4 { text-indent: 20px; } #nnzaecvzmk .gt_indent_5 { text-indent: 25px; } Characteristic Beta 95% CI1 p-value Sepal.Width 0.26 0.17, 0.35 Petal.Width -0.29 -0.57, -0.02 0.039 Petal.Length 1.8 1.5, 2.1 Species2     versicolor — —     setosa 0.87 0.30, 1.4 0.003     virginica -0.36 -0.65, -0.08 0.013 1 CI = Confidence Interval 4.3 Régression logistique Dans le cas de la régression logistique, la variable à expliquer est binaire ou dichotomique. \\(y=\\frac{e^{b_1x_1+b_2x_2+...+b_ix_i+b_0}}{1+e^{b_1x_1+b_2x_2+...+b_ix_i+b_0}}\\) En fait les observations vont prendre la valeur 0 ou 1 pour la variable à expliquer. Par contre le modèle lui ne va pas prendre que des valeurs 0 ou 1. En effet il va modéliser la probabilité que la valeur prise soit 1. Donc les valeurs prises par le modèle vont varier de 0 à 1. 4.3.1 Modélisation L’aspect du modèle sous R est très similaire à la forme utilisée pour les régressions linéaires. Les mêmes opérateurs et écritures sont autorisées. Par contre comme ce n’est pas une régression linéaire, la fonction à appeler est légèrement différente ainsi que les arguments supplémentaires. modele &lt;- glm(Outcome~Pregnancies+Glucose+BloodPressure+SkinThickness+Insulin+BMI+DiabetesPedigreeFunction+ DiabetesPedigreeFunction+Age,data=diabetes,family=binomial(link=&quot;logit&quot;)) summary(modele) ## ## Call: ## glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + ## DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -8.0264511 0.4306345 -18.639 &lt; 2e-16 *** ## Pregnancies 0.1263845 0.0199997 6.319 2.63e-10 *** ## Glucose 0.0337202 0.0022258 15.150 &lt; 2e-16 *** ## BloodPressure -0.0096446 0.0032441 -2.973 0.00295 ** ## SkinThickness 0.0005185 0.0042301 0.123 0.90244 ## Insulin -0.0012426 0.0005786 -2.148 0.03175 * ## BMI 0.0775549 0.0088819 8.732 &lt; 2e-16 *** ## DiabetesPedigreeFunction 0.8877583 0.1860275 4.772 1.82e-06 *** ## Age 0.0129414 0.0057020 2.270 0.02323 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2569.4 on 1999 degrees of freedom ## Residual deviance: 1914.3 on 1991 degrees of freedom ## AIC: 1932.3 ## ## Number of Fisher Scoring iterations: 5 Ici il n’y a pas d’hypothèse à vérifier particulièrement. Nous retrouvons le tableau des coefficients avec les estimations et les p-values. Les Estimates sont d’une interprétation très différents. Pour les variables continues, les coefficients sont interprétables selon leur signe si ils sont significativement différents de 0. Si le signe est négatif alors l’augmentation de la valeur tend à diminuer la probabilité que l’outcome soit égal à 1 et inversement. Pour les variables dichotomiques, en prenant l’exponentielle du coefficient, nous obtenons l’odds ratio: 1) OR=1, la maladie est indépendante du symptôme 2) OR&gt;1, la maladie est plus fréquente pour les individus qui ont le symptôme (var=1). 3) OR&lt;1, la maladie est plus fréquente pour les individus qui n’ont pas le symptôme (var=0). Pour une régression logistique, il n’y a pas de R². Parfois on peut voir un pseudo R². Mais sont utilisation n’est pas recommandé. Sous R, il faut calculer la régression logistique avec la fonction lrm du paquet rms. library(rms) mod1b &lt;- lrm(Outcome~Pregnancies+Glucose+BloodPressure+SkinThickness+Insulin+BMI+DiabetesPedigreeFunction+ DiabetesPedigreeFunction+Age,data=diabetes) print(mod1b) ## Logistic Regression Model ## ## lrm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + ## DiabetesPedigreeFunction + Age, data = diabetes) ## ## Model Likelihood Discrimination Rank Discrim. ## Ratio Test Indexes Indexes ## Obs 2000 LR chi2 655.08 R2 0.386 C 0.837 ## 0 1316 d.f. 8 R2(8,2000)0.276 Dxy 0.675 ## 1 684 Pr(&gt; chi2) &lt;0.0001 R2(8,1350.2)0.381 gamma 0.675 ## max |deriv| 2e-08 Brier 0.154 tau-a 0.304 ## ## Coef S.E. Wald Z Pr(&gt;|Z|) ## Intercept -8.0265 0.4306 -18.64 &lt;0.0001 ## Pregnancies 0.1264 0.0200 6.32 &lt;0.0001 ## Glucose 0.0337 0.0022 15.15 &lt;0.0001 ## BloodPressure -0.0096 0.0032 -2.97 0.0029 ## SkinThickness 0.0005 0.0042 0.12 0.9024 ## Insulin -0.0012 0.0006 -2.15 0.0317 ## BMI 0.0776 0.0089 8.73 &lt;0.0001 ## DiabetesPedigreeFunction 0.8878 0.1860 4.77 &lt;0.0001 ## Age 0.0129 0.0057 2.27 0.0232 modele |&gt; ggstats::ggcoef_table(exponentiate = TRUE) 4.4 Sélection des variables 4.4.1 Régressions pas à pas Cela consiste à comparer des modèles en changer les variables une par une en calculant si la variable améliore ou détériore le modèle. Comme valeur de comparer la fonction utilise l’AIC ou le BIC qui sont des indices de fit du modèle. Soit : 1) on part d’un modèle avec toutes les variables et on enlève au fur et à mesure (backward) 2) on part d’un modèle avec une variable choisie aléatoirement et on ajoute au fur et à mesure (forward) 3) on part d’un modèle avec une variable choisie aléatoirement et on ajoute au fur et à mesure ou on enlève (both ou stepwise) set.seed(42) (modele2 &lt;- step(modele,direction=&quot;both&quot;)) ## Start: AIC=1932.33 ## Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + ## Insulin + BMI + DiabetesPedigreeFunction + DiabetesPedigreeFunction + ## Age ## ## Df Deviance AIC ## - SkinThickness 1 1914.3 1930.3 ## &lt;none&gt; 1914.3 1932.3 ## - Insulin 1 1919.0 1935.0 ## - Age 1 1919.5 1935.5 ## - BloodPressure 1 1923.2 1939.2 ## - DiabetesPedigreeFunction 1 1937.6 1953.6 ## - Pregnancies 1 1955.7 1971.7 ## - BMI 1 1999.9 2015.9 ## - Glucose 1 2203.3 2219.3 ## ## Step: AIC=1930.35 ## Outcome ~ Pregnancies + Glucose + BloodPressure + Insulin + BMI + ## DiabetesPedigreeFunction + Age ## ## Df Deviance AIC ## &lt;none&gt; 1914.3 1930.3 ## + SkinThickness 1 1914.3 1932.3 ## - Age 1 1919.5 1933.5 ## - Insulin 1 1919.7 1933.7 ## - BloodPressure 1 1923.4 1937.4 ## - DiabetesPedigreeFunction 1 1937.8 1951.8 ## - Pregnancies 1 1955.8 1969.8 ## - BMI 1 2009.6 2023.6 ## - Glucose 1 2209.0 2223.0 ## ## Call: glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## Insulin + BMI + DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## (Intercept) Pregnancies Glucose BloodPressure ## -8.027315 0.126371 0.033681 -0.009581 ## Insulin BMI DiabetesPedigreeFunction Age ## -0.001212 0.077874 0.889495 0.012894 ## ## Degrees of Freedom: 1999 Total (i.e. Null); 1992 Residual ## Null Deviance: 2569 ## Residual Deviance: 1914 AIC: 1930 summary(modele2) ## ## Call: ## glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## Insulin + BMI + DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -8.0273146 0.4306244 -18.641 &lt; 2e-16 *** ## Pregnancies 0.1263707 0.0199944 6.320 2.61e-10 *** ## Glucose 0.0336810 0.0022020 15.296 &lt; 2e-16 *** ## BloodPressure -0.0095806 0.0032013 -2.993 0.00276 ** ## Insulin -0.0012123 0.0005228 -2.319 0.02042 * ## BMI 0.0778743 0.0084946 9.167 &lt; 2e-16 *** ## DiabetesPedigreeFunction 0.8894946 0.1855205 4.795 1.63e-06 *** ## Age 0.0128944 0.0056879 2.267 0.02339 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2569.4 on 1999 degrees of freedom ## Residual deviance: 1914.3 on 1992 degrees of freedom ## AIC: 1930.3 ## ## Number of Fisher Scoring iterations: 5 Ces méthodes ne sont pas enthousiasmantes. En effet cela amène à des modèles qui : dépendent du modèles tirés au hasard au début (stepwise/both) sont conservatifs comme la méthode backward qui tend à garder plus de variable que nécessaire nécessite beaucoup de comparaison et donc des approximations sur les tests … Il est à noter que si on veut garder les variables dont les coefficients sont significatifs à 0,05, il suffit de modifier le paramètre k. require(MASS) set.seed(42) (modele2 &lt;- stepAIC(modele,direction=&quot;both&quot;,k=5)) ## Start: AIC=1959.33 ## Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + ## Insulin + BMI + DiabetesPedigreeFunction + DiabetesPedigreeFunction + ## Age ## ## Df Deviance AIC ## - SkinThickness 1 1914.3 1954.3 ## - Insulin 1 1919.0 1959.0 ## &lt;none&gt; 1914.3 1959.3 ## - Age 1 1919.5 1959.5 ## - BloodPressure 1 1923.2 1963.2 ## - DiabetesPedigreeFunction 1 1937.6 1977.6 ## - Pregnancies 1 1955.7 1995.7 ## - BMI 1 1999.9 2039.9 ## - Glucose 1 2203.3 2243.3 ## ## Step: AIC=1954.35 ## Outcome ~ Pregnancies + Glucose + BloodPressure + Insulin + BMI + ## DiabetesPedigreeFunction + Age ## ## Df Deviance AIC ## &lt;none&gt; 1914.3 1954.3 ## - Age 1 1919.5 1954.5 ## - Insulin 1 1919.7 1954.7 ## - BloodPressure 1 1923.4 1958.4 ## + SkinThickness 1 1914.3 1959.3 ## - DiabetesPedigreeFunction 1 1937.8 1972.8 ## - Pregnancies 1 1955.8 1990.8 ## - BMI 1 2009.6 2044.6 ## - Glucose 1 2209.0 2244.0 ## ## Call: glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## Insulin + BMI + DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## (Intercept) Pregnancies Glucose BloodPressure ## -8.027315 0.126371 0.033681 -0.009581 ## Insulin BMI DiabetesPedigreeFunction Age ## -0.001212 0.077874 0.889495 0.012894 ## ## Degrees of Freedom: 1999 Total (i.e. Null); 1992 Residual ## Null Deviance: 2569 ## Residual Deviance: 1914 AIC: 1930 summary(modele2) ## ## Call: ## glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## Insulin + BMI + DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -8.0273146 0.4306244 -18.641 &lt; 2e-16 *** ## Pregnancies 0.1263707 0.0199944 6.320 2.61e-10 *** ## Glucose 0.0336810 0.0022020 15.296 &lt; 2e-16 *** ## BloodPressure -0.0095806 0.0032013 -2.993 0.00276 ** ## Insulin -0.0012123 0.0005228 -2.319 0.02042 * ## BMI 0.0778743 0.0084946 9.167 &lt; 2e-16 *** ## DiabetesPedigreeFunction 0.8894946 0.1855205 4.795 1.63e-06 *** ## Age 0.0128944 0.0056879 2.267 0.02339 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2569.4 on 1999 degrees of freedom ## Residual deviance: 1914.3 on 1992 degrees of freedom ## AIC: 1930.3 ## ## Number of Fisher Scoring iterations: 5 Pour contrer certaines critiques il est possible de personnaliser le démarrage et les variables à disposition à l’aide de l’argument scope. Par exemple pour un stepwise en démarrant de rien. modnull &lt;- glm(Outcome ~ 1,data=diabetes,family=binomial(link=&quot;logit&quot;)) modfull &lt;- glm(Outcome ~ .,data=diabetes,family=binomial(link=&quot;logit&quot;)) (modele3 &lt;- stepAIC(modele,direction=&quot;both&quot;,k=5, scope=list(lower=modnull,upper=modfull))) ## Start: AIC=1959.33 ## Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + ## Insulin + BMI + DiabetesPedigreeFunction + DiabetesPedigreeFunction + ## Age ## ## Df Deviance AIC ## - SkinThickness 1 1914.3 1954.3 ## - Insulin 1 1919.0 1959.0 ## &lt;none&gt; 1914.3 1959.3 ## - Age 1 1919.5 1959.5 ## - BloodPressure 1 1923.2 1963.2 ## - DiabetesPedigreeFunction 1 1937.6 1977.6 ## - Pregnancies 1 1955.7 1995.7 ## - BMI 1 1999.9 2039.9 ## - Glucose 1 2203.3 2243.3 ## ## Step: AIC=1954.35 ## Outcome ~ Pregnancies + Glucose + BloodPressure + Insulin + BMI + ## DiabetesPedigreeFunction + Age ## ## Df Deviance AIC ## &lt;none&gt; 1914.3 1954.3 ## - Age 1 1919.5 1954.5 ## - Insulin 1 1919.7 1954.7 ## - BloodPressure 1 1923.4 1958.4 ## + SkinThickness 1 1914.3 1959.3 ## - DiabetesPedigreeFunction 1 1937.8 1972.8 ## - Pregnancies 1 1955.8 1990.8 ## - BMI 1 2009.6 2044.6 ## - Glucose 1 2209.0 2244.0 ## ## Call: glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## Insulin + BMI + DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## (Intercept) Pregnancies Glucose BloodPressure ## -8.027315 0.126371 0.033681 -0.009581 ## Insulin BMI DiabetesPedigreeFunction Age ## -0.001212 0.077874 0.889495 0.012894 ## ## Degrees of Freedom: 1999 Total (i.e. Null); 1992 Residual ## Null Deviance: 2569 ## Residual Deviance: 1914 AIC: 1930 summary(modele3) ## ## Call: ## glm(formula = Outcome ~ Pregnancies + Glucose + BloodPressure + ## Insulin + BMI + DiabetesPedigreeFunction + Age, family = binomial(link = &quot;logit&quot;), ## data = diabetes) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -8.0273146 0.4306244 -18.641 &lt; 2e-16 *** ## Pregnancies 0.1263707 0.0199944 6.320 2.61e-10 *** ## Glucose 0.0336810 0.0022020 15.296 &lt; 2e-16 *** ## BloodPressure -0.0095806 0.0032013 -2.993 0.00276 ** ## Insulin -0.0012123 0.0005228 -2.319 0.02042 * ## BMI 0.0778743 0.0084946 9.167 &lt; 2e-16 *** ## DiabetesPedigreeFunction 0.8894946 0.1855205 4.795 1.63e-06 *** ## Age 0.0128944 0.0056879 2.267 0.02339 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2569.4 on 1999 degrees of freedom ## Residual deviance: 1914.3 on 1992 degrees of freedom ## AIC: 1930.3 ## ## Number of Fisher Scoring iterations: 5 Il est à noter que les résultats peuvent être donnés par gtsummary modele3 |&gt; tbl_regression(exponentiate = TRUE) |&gt; bold_labels() #qeayjdrzqo table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #qeayjdrzqo thead, #qeayjdrzqo tbody, #qeayjdrzqo tfoot, #qeayjdrzqo tr, #qeayjdrzqo td, #qeayjdrzqo th { border-style: none; } #qeayjdrzqo p { margin: 0; padding: 0; } #qeayjdrzqo .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qeayjdrzqo .gt_caption { padding-top: 4px; padding-bottom: 4px; } #qeayjdrzqo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qeayjdrzqo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #qeayjdrzqo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qeayjdrzqo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qeayjdrzqo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qeayjdrzqo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qeayjdrzqo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qeayjdrzqo .gt_column_spanner_outer:first-child { padding-left: 0; } #qeayjdrzqo .gt_column_spanner_outer:last-child { padding-right: 0; } #qeayjdrzqo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qeayjdrzqo .gt_spanner_row { border-bottom-style: hidden; } #qeayjdrzqo .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #qeayjdrzqo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qeayjdrzqo .gt_from_md > :first-child { margin-top: 0; } #qeayjdrzqo .gt_from_md > :last-child { margin-bottom: 0; } #qeayjdrzqo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qeayjdrzqo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #qeayjdrzqo .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #qeayjdrzqo .gt_row_group_first td { border-top-width: 2px; } #qeayjdrzqo .gt_row_group_first th { border-top-width: 2px; } #qeayjdrzqo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qeayjdrzqo .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #qeayjdrzqo .gt_first_summary_row.thick { border-top-width: 2px; } #qeayjdrzqo .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qeayjdrzqo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qeayjdrzqo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qeayjdrzqo .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #qeayjdrzqo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qeayjdrzqo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qeayjdrzqo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qeayjdrzqo .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qeayjdrzqo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qeayjdrzqo .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qeayjdrzqo .gt_left { text-align: left; } #qeayjdrzqo .gt_center { text-align: center; } #qeayjdrzqo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qeayjdrzqo .gt_font_normal { font-weight: normal; } #qeayjdrzqo .gt_font_bold { font-weight: bold; } #qeayjdrzqo .gt_font_italic { font-style: italic; } #qeayjdrzqo .gt_super { font-size: 65%; } #qeayjdrzqo .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #qeayjdrzqo .gt_asterisk { font-size: 100%; vertical-align: 0; } #qeayjdrzqo .gt_indent_1 { text-indent: 5px; } #qeayjdrzqo .gt_indent_2 { text-indent: 10px; } #qeayjdrzqo .gt_indent_3 { text-indent: 15px; } #qeayjdrzqo .gt_indent_4 { text-indent: 20px; } #qeayjdrzqo .gt_indent_5 { text-indent: 25px; } Characteristic OR1 95% CI1 p-value Pregnancies 1.13 1.09, 1.18 Glucose 1.03 1.03, 1.04 BloodPressure 0.99 0.98, 1.00 0.003 Insulin 1.00 1.00, 1.00 0.020 BMI 1.08 1.06, 1.10 DiabetesPedigreeFunction 2.43 1.69, 3.51 Age 1.01 1.00, 1.02 0.023 1 OR = Odds Ratio, CI = Confidence Interval On peut comparer l’efficacité des modèles en utilisant la commande compare_performance du paquet performance. performance::compare_performance(modele, modele3,metrics=&quot;common&quot;) ## # Comparison of Model Performance Indices ## ## Name | Model | AIC (weights) | BIC (weights) | Tjur&#39;s R2 | RMSE ## --------------------------------------------------------------------- ## modele | glm | 1932.3 (0.270) | 1982.7 (0.022) | 0.310 | 0.393 ## modele3 | glm | 1930.3 (0.730) | 1975.2 (0.978) | 0.310 | 0.393 4.4.2 Régression Ridge, LASSO, Elastic, … Ces méthodes qui seront proposées plus tard sont une alternative au méthodes pas à pas. Elles consiste à pondérer les coefficients et ainsi séléctionner les variables à part de critère mathématique plus robustes. "]]
